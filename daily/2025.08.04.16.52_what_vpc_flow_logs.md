# VPC Flow Logsとは

## What's this file?
> [!NOTE]
> **What**
> 
> VPC Flow Logsとは何かについて記載しています。

## Conclusion (忙しいとき向け)
> [!IMPORTANT]
> **What** : VPC Flow Logsとは何か
> 
> **Answer** : VPC内のネットワークインターフェース（ENI）を出入りするIPトラフィックの情報をキャプチャする機能。セキュリティ分析、ネットワーク監視、トラブルシューティングに使用され、CloudWatch Logs、S3、Kinesis Data Firehoseに出力可能

## 目次

<details>
<summary>目次を開く</summary>

- [VPC Flow Logsの基本概念](#vpc-flow-logsの基本概念)
- [キャプチャ可能な情報](#キャプチャ可能な情報)
- [設定レベルと出力先](#設定レベルと出力先)
- [活用シナリオとベストプラクティス](#活用シナリオとベストプラクティス)

</details>

## VPC Flow Logsの基本概念

### VPC Flow Logsの仕組み

```mermaid
graph TB
    subgraph "VPC内のリソース"
        EC2[EC2インスタンス]
        ALB[ALB]
        NAT[NAT Gateway]
        RDS[RDS]
    end
    
    subgraph "ネットワークインターフェース"
        ENI1[ENI-1]
        ENI2[ENI-2]
        ENI3[ENI-3]
        ENI4[ENI-4]
    end
    
    subgraph "Flow Logs"
        FL[VPC Flow Logs<br/>トラフィック記録]
    end
    
    subgraph "出力先"
        CW[CloudWatch Logs]
        S3[S3 Bucket]
        KDF[Kinesis Data Firehose]
    end
    
    EC2 --> ENI1
    ALB --> ENI2
    NAT --> ENI3
    RDS --> ENI4
    
    ENI1 --> FL
    ENI2 --> FL
    ENI3 --> FL
    ENI4 --> FL
    
    FL --> CW
    FL --> S3
    FL --> KDF
    
    style FL fill:#ff9,stroke:#333,stroke-width:3px
    style CW fill:#9ff,stroke:#333,stroke-width:2px
    style S3 fill:#9f9,stroke:#333,stroke-width:2px
```

### Flow Logsの特徴

| 特徴 | 説明 |
|------|------|
| パケットキャプチャではない | IPヘッダー情報のみ記録（ペイロードは含まない） |
| リアルタイムではない | 数分の遅延あり |
| 追加料金 | データ収集料金＋保存先の料金 |
| 後から有効化可能 | 既存のVPC/サブネット/ENIに追加可能 |
| 無効化可能 | いつでも停止可能（過去ログは残る） |

## キャプチャ可能な情報

### 標準フォーマット

```mermaid
graph LR
    subgraph "基本フィールド"
        F1[version]
        F2[account-id]
        F3[interface-id]
        F4[srcaddr]
        F5[dstaddr]
        F6[srcport]
        F7[dstport]
    end
    
    subgraph "プロトコル情報"
        F8[protocol]
        F9[packets]
        F10[bytes]
        F11[action]
    end
    
    subgraph "時刻情報"
        F12[start]
        F13[end]
        F14[log-status]
    end
    
    F1 --> Example[2 123456789 eni-abc123 10.0.1.5 10.0.2.10 34567 443 6 10 840 1234567890 1234567900 ACCEPT OK]
```

### フィールドの詳細

| フィールド | 説明 | 例 |
|-----------|------|-----|
| version | Flow Logsのバージョン | 2 |
| account-id | AWSアカウントID | 123456789012 |
| interface-id | ENIのID | eni-1234567890abcdef0 |
| srcaddr | 送信元IPアドレス | 10.0.1.5 |
| dstaddr | 宛先IPアドレス | 10.0.2.10 |
| srcport | 送信元ポート | 34567 |
| dstport | 宛先ポート | 443 |
| protocol | プロトコル番号 | 6 (TCP), 17 (UDP) |
| packets | パケット数 | 10 |
| bytes | バイト数 | 840 |
| action | ACCEPT/REJECT | ACCEPT |
| log-status | ログステータス | OK, NODATA, SKIPDATA |

### カスタムフォーマット

#### 追加可能なフィールド

| フィールド名 | 説明 |
|------------|------|
| vpc-id | VPC ID |
| subnet-id | サブネットID |
| instance-id | インスタンスID |
| tcp-flags | TCPフラグ |
| type | IPv4/IPv6 |
| pkt-srcaddr | パケットレベルの送信元IP |
| pkt-dstaddr | パケットレベルの宛先IP |
| region | リージョン |
| az-id | アベイラビリティゾーンID |
| sublocation-type | Wavelength/Outpost等 |
| flow-direction | ingress/egress |

## 設定レベルと出力先

### Flow Logs設定レベル

```mermaid
graph TD
    subgraph "設定可能なレベル"
        VPC[VPC レベル<br/>VPC内全トラフィック]
        Subnet[サブネットレベル<br/>特定サブネット内]
        ENI[ENI レベル<br/>特定インターフェース]
    end
    
    subgraph "キャプチャ対象"
        ALL[ALL<br/>すべてのトラフィック]
        ACCEPT[ACCEPT<br/>許可されたトラフィック]
        REJECT[REJECT<br/>拒否されたトラフィック]
    end
    
    VPC --> ALL
    VPC --> ACCEPT
    VPC --> REJECT
    Subnet --> ALL
    ENI --> ALL
    
    style VPC fill:#ff9,stroke:#333,stroke-width:3px
    style ALL fill:#9ff,stroke:#333,stroke-width:2px
```

### 出力先の比較

| 出力先 | 用途 | メリット | デメリット |
|--------|------|--------|-----------|
| CloudWatch Logs | リアルタイム分析 | ・Insights で即座に分析<br>・アラーム設定可能 | ・保存コスト高<br>・長期保存に不向き |
| S3 | 長期保存・大量データ | ・低コスト<br>・Athenaで分析可能<br>・ライフサイクル管理 | ・リアルタイム性低<br>・直接検索不可 |
| Kinesis Data Firehose | ストリーミング処理 | ・リアルタイム処理<br>・他サービス連携<br>・自動変換 | ・設定が複雑<br>・追加コスト |

### Terraformでの実装例

```hcl
# VPCレベルのFlow Logs（S3出力）
resource "aws_flow_log" "vpc_s3" {
  log_destination_type = "s3"
  log_destination      = aws_s3_bucket.flow_logs.arn
  traffic_type         = "ALL"
  vpc_id               = aws_vpc.main.id
  
  # カスタムフォーマット
  log_format = "$${version} $${account-id} $${interface-id} $${srcaddr} $${dstaddr} $${srcport} $${dstport} $${protocol} $${packets} $${bytes} $${start} $${end} $${action} $${log-status} $${vpc-id} $${subnet-id} $${instance-id} $${tcp-flags} $${type} $${pkt-srcaddr} $${pkt-dstaddr}"
  
  tags = {
    Name = "vpc-flow-logs-s3"
  }
}

# サブネットレベルのFlow Logs（CloudWatch Logs出力）
resource "aws_flow_log" "subnet_cloudwatch" {
  iam_role_arn         = aws_iam_role.flow_log.arn
  log_destination_type = "cloud-watch-logs"
  log_group_name       = aws_cloudwatch_log_group.flow_log.name
  traffic_type         = "REJECT"  # 拒否トラフィックのみ
  subnet_id            = aws_subnet.private.id
}

# S3バケット（Flow Logs保存用）
resource "aws_s3_bucket" "flow_logs" {
  bucket = "my-vpc-flow-logs"
}

resource "aws_s3_bucket_lifecycle_configuration" "flow_logs" {
  bucket = aws_s3_bucket.flow_logs.id
  
  rule {
    id     = "archive-old-logs"
    status = "Enabled"
    
    transition {
      days          = 30
      storage_class = "STANDARD_IA"
    }
    
    transition {
      days          = 90
      storage_class = "GLACIER"
    }
    
    expiration {
      days = 365
    }
  }
}
```

## 活用シナリオとベストプラクティス

### 主な活用シナリオ

```mermaid
graph LR
    subgraph "セキュリティ"
        S1[不正アクセス検知]
        S2[データ漏洩調査]
        S3[コンプライアンス監査]
    end
    
    subgraph "ネットワーク分析"
        N1[トラフィックパターン分析]
        N2[ボトルネック特定]
        N3[コスト最適化]
    end
    
    subgraph "トラブルシューティング"
        T1[接続性問題調査]
        T2[パフォーマンス問題]
        T3[設定ミス検出]
    end
    
    FL[VPC Flow Logs]
    
    FL --> S1
    FL --> N1
    FL --> T1
```

### セキュリティ分析の例

```sql
-- Athenaでの分析クエリ例

-- 1. 特定ポートへの接続試行を検出
SELECT 
    srcaddr,
    COUNT(*) as attempt_count,
    COUNT(DISTINCT dstport) as unique_ports
FROM vpc_flow_logs
WHERE action = 'REJECT'
    AND dstport IN (22, 3389, 3306, 5432)
    AND date = '2024-01-15'
GROUP BY srcaddr
HAVING COUNT(*) > 100
ORDER BY attempt_count DESC;

-- 2. 大量データ転送の検出
SELECT 
    srcaddr,
    dstaddr,
    SUM(bytes) as total_bytes,
    COUNT(*) as connection_count
FROM vpc_flow_logs
WHERE action = 'ACCEPT'
    AND date = '2024-01-15'
GROUP BY srcaddr, dstaddr
HAVING SUM(bytes) > 1073741824  -- 1GB以上
ORDER BY total_bytes DESC;

-- 3. 異常な通信パターンの検出
SELECT 
    srcaddr,
    COUNT(DISTINCT dstaddr) as unique_destinations,
    COUNT(DISTINCT dstport) as unique_ports
FROM vpc_flow_logs
WHERE action = 'ACCEPT'
    AND date = '2024-01-15'
GROUP BY srcaddr
HAVING COUNT(DISTINCT dstaddr) > 50
    OR COUNT(DISTINCT dstport) > 20;
```

### コスト最適化

```mermaid
graph TD
    subgraph "コスト要因"
        C1[データ収集料金<br/>$0.50/GB]
        C2[保存料金<br/>出力先による]
        C3[分析料金<br/>ツールによる]
    end
    
    subgraph "最適化方法"
        O1[必要なトラフィックタイプのみ記録]
        O2[サンプリングの活用]
        O3[S3ライフサイクル設定]
        O4[不要なフィールド除外]
    end
    
    C1 --> O1
    C2 --> O3
    C3 --> O4
```

### ベストプラクティス

1. **適切なレベルでの有効化**
   - セキュリティ重視: VPCレベルで全トラフィック
   - コスト重視: 必要なサブネット/ENIのみ
   - トラブルシューティング: 一時的に有効化

2. **出力先の選択**

   | 分析タイプ | 推奨出力先 | 保持期間 | 用途 |
   |----------|-----------|---------|------|
   | リアルタイム分析 | CloudWatch Logs | 7-30日 | 即時分析、アラート |
   | 長期保存 | S3 | 365日以上 | コンプライアンス、監査 |
   | ストリーミング分析 | Kinesis Data Firehose | - | ElasticSearch/Splunkへの連携 |

3. **データ分析パイプライン**
   ```mermaid
   graph LR
       FL[Flow Logs] --> S3[S3]
       S3 --> Glue[AWS Glue<br/>ETL]
       Glue --> Athena[Athena<br/>分析]
       Athena --> QS[QuickSight<br/>可視化]
       
       FL --> CW[CloudWatch]
       CW --> Insights[Insights<br/>リアルタイム分析]
       Insights --> Alarm[CloudWatch Alarms]
   ```

## 関連
- [VPC Flow Logs公式ドキュメント](https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html)
- [Flow Logsのレコード形式](https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-records-examples.html)
- [Athenaを使用したFlow Logs分析](https://docs.aws.amazon.com/athena/latest/ug/vpc-flow-logs.html)
- [Flow Logsの料金](https://aws.amazon.com/vpc/pricing/)